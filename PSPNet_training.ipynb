{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":64367,"status":"ok","timestamp":1649643056737,"user":{"displayName":"中田光隆","userId":"06690068059315868411"},"user_tz":-540},"id":"H9kFD-8gqbh5","outputId":"fc2eda2a-a4a7-442e-e056-06e914cc045f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["import os\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","SAVE_MODEL_PATH = '/content/drive/MyDrive/Colab Notebooks/semantic_segmentation/model/'  # モデルの保存先\n","\n","# 保存先のディレクトリを作成する\n","os.makedirs(SAVE_MODEL_PATH, exist_ok=True)"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1649643056739,"user":{"displayName":"中田光隆","userId":"06690068059315868411"},"user_tz":-540},"id":"XkCe5vRL3bYl","outputId":"4e0b921d-3bba-4602-eb4f-370744d0613f"},"outputs":[{"output_type":"stream","name":"stdout","text":["['',\n"," '/content',\n"," '/env/python',\n"," '/usr/lib/python37.zip',\n"," '/usr/lib/python3.7',\n"," '/usr/lib/python3.7/lib-dynload',\n"," '/usr/local/lib/python3.7/dist-packages',\n"," '/usr/lib/python3/dist-packages',\n"," '/usr/local/lib/python3.7/dist-packages/IPython/extensions',\n"," '/root/.ipython',\n"," '/content/drive/My Drive/Colab Notebooks/semantic_segmentation',\n"," '/content/drive/My Drive/Colab Notebooks/semantic_segmentation/utils']\n"]}],"source":["import sys\n","import pprint\n","\n","# モジュールのインポートが行えるように「VOC2021_SSDのパスを登録\n","# 以下のパスは環境に合わせて書き換える必要があります\n","sys.path.append('/content/drive/My Drive/Colab Notebooks/semantic_segmentation')\n","sys.path.append('/content/drive/My Drive/Colab Notebooks/semantic_segmentation/utils')\n","\n","pprint.pprint(sys.path)"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1649643056740,"user":{"displayName":"中田光隆","userId":"06690068059315868411"},"user_tz":-540},"id":"PXc9A8rq3dlX"},"outputs":[],"source":["import os\n","import urllib.request\n","import zipfile\n","import tarfile"]},{"cell_type":"markdown","metadata":{"id":"pfqYwC1W5HO8"},"source":["## データのダウンロード"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1649643056741,"user":{"displayName":"中田光隆","userId":"06690068059315868411"},"user_tz":-540},"id":"pNl2-89H3gRb"},"outputs":[],"source":["# フォルダ「data」が存在しない場合は作成する\n","data_dir = \"./data/\"\n","if not os.path.exists(data_dir):\n","    os.mkdir(data_dir)"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":25591,"status":"ok","timestamp":1649643082321,"user":{"displayName":"中田光隆","userId":"06690068059315868411"},"user_tz":-540},"id":"8Dq5gwzT3h_o"},"outputs":[],"source":["# VOC2012のデータセットをここからダウンロード\n","url = \"http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar\"\n","target_path = os.path.join(data_dir, \"VOCtrainval_11-May-2012.tar\") \n","\n","if not os.path.exists(target_path):\n","    urllib.request.urlretrieve(url, target_path)\n","    \n","    tar = tarfile.TarFile(target_path)  # tarファイルを読み込み\n","    tar.extractall(data_dir)  # tarを解凍\n","    tar.close()  # tarファイルをクローズ"]},{"cell_type":"markdown","metadata":{"id":"BzLLtV2K3JhF"},"source":["# 事前準備"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":8422,"status":"ok","timestamp":1649643090736,"user":{"displayName":"中田光隆","userId":"06690068059315868411"},"user_tz":-540},"id":"Usm1Av9T3AFm"},"outputs":[],"source":["# ライブラリのインポート\n","import random\n","import math\n","import time\n","import pandas as pd\n","import numpy as np\n","\n","import torch\n","import torch.utils.data as data\n","import torch.nn as nn\n","import torch.nn.init as init\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","from utils.dataloader import make_datapath_list, DataTransform, VOCDataset\n","from utils.pspnet import PSPNet"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1649643090737,"user":{"displayName":"中田光隆","userId":"06690068059315868411"},"user_tz":-540},"id":"qZ-ETTxy3FrZ"},"outputs":[],"source":["# 乱数のシードを設定\n","torch.manual_seed(1234)\n","np.random.seed(1234)\n","random.seed(1234)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1649643090738,"user":{"displayName":"中田光隆","userId":"06690068059315868411"},"user_tz":-540},"id":"SGCrvvNe6nbD","outputId":"a77f6366-6168-4e1b-e1b4-326de9d910b2"},"outputs":[{"output_type":"stream","name":"stdout","text":["使用デバイス： cuda:0\n"]}],"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(\"使用デバイス：\", device)"]},{"cell_type":"markdown","metadata":{"id":"_bHjNo2a3FJe"},"source":["# DataLoader"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1649643090739,"user":{"displayName":"中田光隆","userId":"06690068059315868411"},"user_tz":-540},"id":"jrKhDRj-3VMQ"},"outputs":[],"source":["# ファイルパスリスト作成\n","rootpath = \"./data/VOCdevkit/VOC2012/\"\n","train_img_list, train_anno_list, val_img_list, val_anno_list = make_datapath_list(\n","    rootpath=rootpath)\n","\n","# Dataset作成\n","# (RGB)の色の平均値と標準偏差\n","color_mean = (0.485, 0.456, 0.406)\n","color_std = (0.229, 0.224, 0.225)\n","\n","train_dataset = VOCDataset(train_img_list, train_anno_list, phase=\"train\", transform=DataTransform(\n","    input_size=475, color_mean=color_mean, color_std=color_std))\n","\n","val_dataset = VOCDataset(val_img_list, val_anno_list, phase=\"val\", transform=DataTransform(\n","    input_size=475, color_mean=color_mean, color_std=color_std))\n","\n","# DataLoader作成\n","batch_size = 8\n","\n","train_dataloader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","\n","val_dataloader = data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","\n","# 辞書型変数にまとめる\n","dataloaders_dict = {\"train\": train_dataloader, \"val\": val_dataloader}"]},{"cell_type":"markdown","metadata":{"id":"VFYx7pNK3rn-"},"source":["# モデルの作成"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":893,"status":"ok","timestamp":1649643091621,"user":{"displayName":"中田光隆","userId":"06690068059315868411"},"user_tz":-540},"id":"qd2txZpk31aS","outputId":"a0207b95-01d5-44e3-9285-ff37720cf71b"},"outputs":[{"output_type":"stream","name":"stdout","text":["ネットワーク設定完了：学習済みの重みをロードしました\n"]}],"source":["# ファインチューニングでPSPNetを作成\n","# ADE20Kデータセットの学習済みモデルを使用、ADE20Kはクラス数が150です\n","net = PSPNet(n_classes=150)\n","\n","# ADE20K学習済みパラメータをロード\n","#state_dict = torch.load(f\"{SAVE_MODEL_PATH}pspnet50_ADE20K.pth\")\n","#net.load_state_dict(state_dict)\n","\n","# 分類用の畳み込み層を、出力数21のものにつけかえる\n","n_classes = 21\n","net.decode_feature.classification = nn.Conv2d(\n","    in_channels=512, out_channels=n_classes, kernel_size=1, stride=1, padding=0)\n","\n","net.aux.classification = nn.Conv2d(\n","    in_channels=256, out_channels=n_classes, kernel_size=1, stride=1, padding=0)\n","\n","# 付け替えた畳み込み層を初期化する。活性化関数がシグモイド関数なのでXavierを使用する。\n","\n","\n","def weights_init(m):\n","    if isinstance(m, nn.Conv2d):\n","        nn.init.xavier_normal_(m.weight.data)\n","        if m.bias is not None:  # バイアス項がある場合\n","            nn.init.constant_(m.bias, 0.0)\n","\n","\n","net.decode_feature.classification.apply(weights_init)\n","net.aux.classification.apply(weights_init)\n","\n","print('ネットワーク設定完了：学習済みの重みをロードしました')"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1649643091622,"user":{"displayName":"中田光隆","userId":"06690068059315868411"},"user_tz":-540},"id":"8UHRG19A5hrI","outputId":"fb893815-95ae-4e3d-c363-9d79d32384b9"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["PSPNet(\n","  (feature_conv): FeatureMap_convolution(\n","    (cbnr_1): conv2DBatchNormRelu(\n","      (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (cbnr_2): conv2DBatchNormRelu(\n","      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (cbnr_3): conv2DBatchNormRelu(\n","      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  )\n","  (feature_res_1): ResidualBlockPSP(\n","    (block1): bottleNeckPSP(\n","      (cbr_1): conv2DBatchNormRelu(\n","        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cbr_2): conv2DBatchNormRelu(\n","        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cb_3): conv2DBatchNorm(\n","        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (cb_residual): conv2DBatchNorm(\n","        (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (block2): bottleNeckIdentifyPSP(\n","      (cbr_1): conv2DBatchNormRelu(\n","        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cbr_2): conv2DBatchNormRelu(\n","        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cb_3): conv2DBatchNorm(\n","        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (block3): bottleNeckIdentifyPSP(\n","      (cbr_1): conv2DBatchNormRelu(\n","        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cbr_2): conv2DBatchNormRelu(\n","        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cb_3): conv2DBatchNorm(\n","        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (feature_res_2): ResidualBlockPSP(\n","    (block1): bottleNeckPSP(\n","      (cbr_1): conv2DBatchNormRelu(\n","        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cbr_2): conv2DBatchNormRelu(\n","        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cb_3): conv2DBatchNorm(\n","        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (cb_residual): conv2DBatchNorm(\n","        (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (block2): bottleNeckIdentifyPSP(\n","      (cbr_1): conv2DBatchNormRelu(\n","        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cbr_2): conv2DBatchNormRelu(\n","        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cb_3): conv2DBatchNorm(\n","        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (block3): bottleNeckIdentifyPSP(\n","      (cbr_1): conv2DBatchNormRelu(\n","        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cbr_2): conv2DBatchNormRelu(\n","        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cb_3): conv2DBatchNorm(\n","        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (block4): bottleNeckIdentifyPSP(\n","      (cbr_1): conv2DBatchNormRelu(\n","        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cbr_2): conv2DBatchNormRelu(\n","        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cb_3): conv2DBatchNorm(\n","        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (feature_dilated_res_1): ResidualBlockPSP(\n","    (block1): bottleNeckPSP(\n","      (cbr_1): conv2DBatchNormRelu(\n","        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cbr_2): conv2DBatchNormRelu(\n","        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cb_3): conv2DBatchNorm(\n","        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (cb_residual): conv2DBatchNorm(\n","        (conv): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (block2): bottleNeckIdentifyPSP(\n","      (cbr_1): conv2DBatchNormRelu(\n","        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cbr_2): conv2DBatchNormRelu(\n","        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cb_3): conv2DBatchNorm(\n","        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (block3): bottleNeckIdentifyPSP(\n","      (cbr_1): conv2DBatchNormRelu(\n","        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cbr_2): conv2DBatchNormRelu(\n","        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cb_3): conv2DBatchNorm(\n","        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (block4): bottleNeckIdentifyPSP(\n","      (cbr_1): conv2DBatchNormRelu(\n","        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cbr_2): conv2DBatchNormRelu(\n","        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cb_3): conv2DBatchNorm(\n","        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (block5): bottleNeckIdentifyPSP(\n","      (cbr_1): conv2DBatchNormRelu(\n","        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cbr_2): conv2DBatchNormRelu(\n","        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cb_3): conv2DBatchNorm(\n","        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (block6): bottleNeckIdentifyPSP(\n","      (cbr_1): conv2DBatchNormRelu(\n","        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cbr_2): conv2DBatchNormRelu(\n","        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cb_3): conv2DBatchNorm(\n","        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (feature_dilated_res_2): ResidualBlockPSP(\n","    (block1): bottleNeckPSP(\n","      (cbr_1): conv2DBatchNormRelu(\n","        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cbr_2): conv2DBatchNormRelu(\n","        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n","        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cb_3): conv2DBatchNorm(\n","        (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (cb_residual): conv2DBatchNorm(\n","        (conv): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (block2): bottleNeckIdentifyPSP(\n","      (cbr_1): conv2DBatchNormRelu(\n","        (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cbr_2): conv2DBatchNormRelu(\n","        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n","        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cb_3): conv2DBatchNorm(\n","        (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","    (block3): bottleNeckIdentifyPSP(\n","      (cbr_1): conv2DBatchNormRelu(\n","        (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cbr_2): conv2DBatchNormRelu(\n","        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n","        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (cb_3): conv2DBatchNorm(\n","        (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (batchnorm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (pyramid_pooling): PyramidPooling(\n","    (avpool_1): AdaptiveAvgPool2d(output_size=6)\n","    (cbr_1): conv2DBatchNormRelu(\n","      (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (avpool_2): AdaptiveAvgPool2d(output_size=3)\n","    (cbr_2): conv2DBatchNormRelu(\n","      (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (avpool_3): AdaptiveAvgPool2d(output_size=2)\n","    (cbr_3): conv2DBatchNormRelu(\n","      (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (avpool_4): AdaptiveAvgPool2d(output_size=1)\n","    (cbr_4): conv2DBatchNormRelu(\n","      (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (decode_feature): DecodePSPFeature(\n","    (cbr): conv2DBatchNormRelu(\n","      (conv): Conv2d(4096, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (dropout): Dropout2d(p=0.1, inplace=False)\n","    (classification): Conv2d(512, 21, kernel_size=(1, 1), stride=(1, 1))\n","  )\n","  (aux): AuxiliaryPSPlayers(\n","    (cbr): conv2DBatchNormRelu(\n","      (conv): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (dropout): Dropout2d(p=0.1, inplace=False)\n","    (classification): Conv2d(256, 21, kernel_size=(1, 1), stride=(1, 1))\n","  )\n",")"]},"metadata":{},"execution_count":11}],"source":["net"]},{"cell_type":"markdown","metadata":{"id":"iShpIMjZ5jkU"},"source":["# 損失関数の定義"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1649643091623,"user":{"displayName":"中田光隆","userId":"06690068059315868411"},"user_tz":-540},"id":"q6IvoB-15lvf"},"outputs":[],"source":["# 損失関数の設定\n","class PSPLoss(nn.Module):\n","    \"\"\"PSPNetの損失関数のクラスです。\"\"\"\n","\n","    def __init__(self, aux_weight=0.4):\n","        super(PSPLoss, self).__init__()\n","        self.aux_weight = aux_weight  # aux_lossの重み\n","\n","    def forward(self, outputs, targets):\n","        \"\"\"\n","        損失関数の計算。\n","\n","        Parameters\n","        ----------\n","        outputs : PSPNetの出力(tuple)\n","            (output=torch.Size([num_batch, 21, 475, 475]), output_aux=torch.Size([num_batch, 21, 475, 475]))。\n","\n","        targets : [num_batch, 475, 475]\n","            正解のアノテーション情報\n","\n","        Returns\n","        -------\n","        loss : テンソル\n","            損失の値\n","        \"\"\"\n","\n","        loss = F.cross_entropy(outputs[0], targets, reduction='mean')\n","        loss_aux = F.cross_entropy(outputs[1], targets, reduction='mean')\n","\n","        return loss+self.aux_weight*loss_aux\n","\n","\n","criterion = PSPLoss(aux_weight=0.4)"]},{"cell_type":"markdown","metadata":{"id":"tNqJ6UgU5ofE"},"source":["# 最適化手法の設定"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1649643091624,"user":{"displayName":"中田光隆","userId":"06690068059315868411"},"user_tz":-540},"id":"ACLmFgR05veH"},"outputs":[],"source":["# ファインチューニングなので、学習率は小さく\n","optimizer = optim.SGD([\n","    {'params': net.feature_conv.parameters(), 'lr': 1e-3},\n","    {'params': net.feature_res_1.parameters(), 'lr': 1e-3},\n","    {'params': net.feature_res_2.parameters(), 'lr': 1e-3},\n","    {'params': net.feature_dilated_res_1.parameters(), 'lr': 1e-3},\n","    {'params': net.feature_dilated_res_2.parameters(), 'lr': 1e-3},\n","    {'params': net.pyramid_pooling.parameters(), 'lr': 1e-3},\n","    {'params': net.decode_feature.parameters(), 'lr': 1e-2},\n","    {'params': net.aux.parameters(), 'lr': 1e-2},\n","], momentum=0.9, weight_decay=0.0001)\n","\n","\n","# スケジューラーの設定\n","def lambda_epoch(epoch):\n","    max_epoch = 30\n","    return math.pow((1-epoch/max_epoch), 0.9)\n","\n","\n","scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda_epoch)"]},{"cell_type":"markdown","metadata":{"id":"Y9pT01Fy50-W"},"source":["# 学習"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":522,"status":"ok","timestamp":1649643092138,"user":{"displayName":"中田光隆","userId":"06690068059315868411"},"user_tz":-540},"id":"vqizkFpM5yC1"},"outputs":[],"source":["# モデルを学習させる関数を作成\n","\n","\n","def train_model(net, dataloaders_dict, criterion, scheduler, optimizer, num_epochs):\n","\n","    # ネットワークをGPUへ\n","    net.to(device)\n","\n","    # ネットワークがある程度固定であれば、高速化させる\n","    torch.backends.cudnn.benchmark = True\n","\n","    # 画像の枚数\n","    num_train_imgs = len(dataloaders_dict[\"train\"].dataset)\n","    num_val_imgs = len(dataloaders_dict[\"val\"].dataset)\n","    batch_size = dataloaders_dict[\"train\"].batch_size\n","\n","    # イテレーションカウンタをセット\n","    iteration = 1\n","    logs = []\n","\n","    # multiple minibatch\n","    batch_multiplier = 3\n","\n","    # epochのループ\n","    for epoch in range(num_epochs):\n","\n","        # 開始時刻を保存\n","        t_epoch_start = time.time()\n","        t_iter_start = time.time()\n","        epoch_train_loss = 0.0  # epochの損失和\n","        epoch_val_loss = 0.0  # epochの損失和\n","\n","        print('-------------')\n","        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n","        print('-------------')\n","\n","        # epochごとの訓練と検証のループ\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                net.train()  # モデルを訓練モードに\n","                scheduler.step()  # 最適化schedulerの更新\n","                optimizer.zero_grad()\n","                print('（train）')\n","\n","            else:\n","                if((epoch+1) % 5 == 0):\n","                    net.eval()   # モデルを検証モードに\n","                    print('-------------')\n","                    print('（val）')\n","                else:\n","                    # 検証は5回に1回だけ行う\n","                    continue\n","\n","            # データローダーからminibatchずつ取り出すループ\n","            count = 0  # multiple minibatch\n","            for imges, anno_class_imges in dataloaders_dict[phase]:\n","                # ミニバッチがサイズが1だと、バッチノーマライゼーションでエラーになるのでさける\n","                # issue #186より不要なのでコメントアウト\n","                # if imges.size()[0] == 1:\n","                #     continue\n","\n","                # GPUが使えるならGPUにデータを送る\n","                imges = imges.to(device)\n","                anno_class_imges = anno_class_imges.to(device)\n","\n","                \n","                # multiple minibatchでのパラメータの更新\n","                if (phase == 'train') and (count == 0):\n","                    optimizer.step()\n","                    optimizer.zero_grad()\n","                    count = batch_multiplier\n","\n","                # 順伝搬（forward）計算\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    outputs = net(imges)\n","                    loss = criterion(outputs, anno_class_imges.long()) / batch_multiplier\n","\n","                    # 訓練時はバックプロパゲーション\n","                    if phase == 'train':\n","                        loss.backward()  # 勾配の計算\n","                        count -= 1  # multiple minibatch\n","\n","                        if (iteration % 10 == 0):  # 10iterに1度、lossを表示\n","                            t_iter_finish = time.time()\n","                            duration = t_iter_finish - t_iter_start\n","                            print('イテレーション {} || Loss: {:.4f} || 10iter: {:.4f} sec.'.format(\n","                                iteration, loss.item()/batch_size*batch_multiplier, duration))\n","                            t_iter_start = time.time()\n","\n","                        epoch_train_loss += loss.item() * batch_multiplier\n","                        iteration += 1\n","\n","                    # 検証時\n","                    else:\n","                        epoch_val_loss += loss.item() * batch_multiplier\n","\n","        # epochのphaseごとのlossと正解率\n","        t_epoch_finish = time.time()\n","        print('-------------')\n","        print('epoch {} || Epoch_TRAIN_Loss:{:.4f} ||Epoch_VAL_Loss:{:.4f}'.format(\n","            epoch+1, epoch_train_loss/num_train_imgs, epoch_val_loss/num_val_imgs))\n","        print('timer:  {:.4f} sec.'.format(t_epoch_finish - t_epoch_start))\n","        t_epoch_start = time.time()\n","\n","        # ログを保存\n","        log_epoch = {'epoch': epoch+1, 'train_loss': epoch_train_loss /\n","                     num_train_imgs, 'val_loss': epoch_val_loss/num_val_imgs}\n","        logs.append(log_epoch)\n","        df = pd.DataFrame(logs)\n","        df.to_csv(\"log_output.csv\")\n","\n","    # 最後のネットワークを保存する\n","    torch.save(net.state_dict(), SAVE_MODEL_PATH + 'pspnet50_' + str(epoch+1) + '.pth')"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZI9SmjGt58Vc","executionInfo":{"status":"ok","timestamp":1649651391511,"user_tz":-540,"elapsed":8299379,"user":{"displayName":"中田光隆","userId":"06690068059315868411"}},"outputId":"80305202-2259-4448-df24-8cacb126882f"},"outputs":[{"output_type":"stream","name":"stdout","text":["-------------\n","Epoch 1/30\n","-------------\n","（train）\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["イテレーション 10 || Loss: 0.4423 || 10iter: 19.7955 sec.\n","イテレーション 20 || Loss: 0.4217 || 10iter: 13.0485 sec.\n","イテレーション 30 || Loss: 0.2538 || 10iter: 13.0458 sec.\n","イテレーション 40 || Loss: 0.3216 || 10iter: 13.0660 sec.\n","イテレーション 50 || Loss: 0.1643 || 10iter: 13.0802 sec.\n","イテレーション 60 || Loss: 0.1780 || 10iter: 13.0171 sec.\n","イテレーション 70 || Loss: 0.1726 || 10iter: 13.0480 sec.\n","イテレーション 80 || Loss: 0.1664 || 10iter: 13.0760 sec.\n","イテレーション 90 || Loss: 0.1581 || 10iter: 13.0398 sec.\n","イテレーション 100 || Loss: 0.2470 || 10iter: 13.0068 sec.\n","イテレーション 110 || Loss: 0.2624 || 10iter: 13.0610 sec.\n","イテレーション 120 || Loss: 0.2602 || 10iter: 13.0653 sec.\n","イテレーション 130 || Loss: 0.1276 || 10iter: 13.0477 sec.\n","イテレーション 140 || Loss: 0.1337 || 10iter: 12.9329 sec.\n","イテレーション 150 || Loss: 0.2243 || 10iter: 12.9707 sec.\n","イテレーション 160 || Loss: 0.2263 || 10iter: 13.0418 sec.\n","イテレーション 170 || Loss: 0.2641 || 10iter: 13.0484 sec.\n","イテレーション 180 || Loss: 0.3682 || 10iter: 12.9890 sec.\n","-------------\n","epoch 1 || Epoch_TRAIN_Loss:0.2346 ||Epoch_VAL_Loss:0.0000\n","timer:  265.9515 sec.\n","-------------\n","Epoch 2/30\n","-------------\n","（train）\n","イテレーション 190 || Loss: 0.1556 || 10iter: 8.7900 sec.\n","イテレーション 200 || Loss: 0.1712 || 10iter: 12.9817 sec.\n","イテレーション 210 || Loss: 0.1255 || 10iter: 13.0262 sec.\n","イテレーション 220 || Loss: 0.1850 || 10iter: 12.9853 sec.\n","イテレーション 230 || Loss: 0.1800 || 10iter: 13.0099 sec.\n","イテレーション 240 || Loss: 0.1221 || 10iter: 12.9875 sec.\n","イテレーション 250 || Loss: 0.1969 || 10iter: 13.0189 sec.\n","イテレーション 260 || Loss: 0.0968 || 10iter: 13.0261 sec.\n","イテレーション 270 || Loss: 0.1922 || 10iter: 13.0471 sec.\n","イテレーション 280 || Loss: 0.1955 || 10iter: 13.0371 sec.\n","イテレーション 290 || Loss: 0.1464 || 10iter: 13.0246 sec.\n","イテレーション 300 || Loss: 0.0928 || 10iter: 13.0382 sec.\n","イテレーション 310 || Loss: 0.2445 || 10iter: 13.1194 sec.\n","イテレーション 320 || Loss: 0.1469 || 10iter: 13.0388 sec.\n","イテレーション 330 || Loss: 0.2912 || 10iter: 13.0062 sec.\n","イテレーション 340 || Loss: 0.1607 || 10iter: 13.0330 sec.\n","イテレーション 350 || Loss: 0.1999 || 10iter: 13.0613 sec.\n","イテレーション 360 || Loss: 0.1593 || 10iter: 12.9698 sec.\n","-------------\n","epoch 2 || Epoch_TRAIN_Loss:0.1882 ||Epoch_VAL_Loss:0.0000\n","timer:  259.0046 sec.\n","-------------\n","Epoch 3/30\n","-------------\n","（train）\n","イテレーション 370 || Loss: 0.1326 || 10iter: 4.5630 sec.\n","イテレーション 380 || Loss: 0.1467 || 10iter: 12.9576 sec.\n","イテレーション 390 || Loss: 0.2597 || 10iter: 13.0529 sec.\n","イテレーション 400 || Loss: 0.1263 || 10iter: 13.0314 sec.\n","イテレーション 410 || Loss: 0.1613 || 10iter: 12.9564 sec.\n","イテレーション 420 || Loss: 0.1634 || 10iter: 12.9903 sec.\n","イテレーション 430 || Loss: 0.1798 || 10iter: 13.0565 sec.\n","イテレーション 440 || Loss: 0.1348 || 10iter: 13.0166 sec.\n","イテレーション 450 || Loss: 0.2423 || 10iter: 13.0053 sec.\n","イテレーション 460 || Loss: 0.1475 || 10iter: 13.0149 sec.\n","イテレーション 470 || Loss: 0.1386 || 10iter: 12.9929 sec.\n","イテレーション 480 || Loss: 0.2125 || 10iter: 12.9858 sec.\n","イテレーション 490 || Loss: 0.1476 || 10iter: 13.0212 sec.\n","イテレーション 500 || Loss: 0.1728 || 10iter: 13.0133 sec.\n","イテレーション 510 || Loss: 0.1953 || 10iter: 13.0800 sec.\n","イテレーション 520 || Loss: 0.3550 || 10iter: 13.0297 sec.\n","イテレーション 530 || Loss: 0.1855 || 10iter: 13.0637 sec.\n","イテレーション 540 || Loss: 0.1227 || 10iter: 13.0262 sec.\n","-------------\n","epoch 3 || Epoch_TRAIN_Loss:0.1858 ||Epoch_VAL_Loss:0.0000\n","timer:  258.9170 sec.\n","-------------\n","Epoch 4/30\n","-------------\n","（train）\n","イテレーション 550 || Loss: 0.2563 || 10iter: 0.3038 sec.\n","イテレーション 560 || Loss: 0.2069 || 10iter: 13.0235 sec.\n","イテレーション 570 || Loss: 0.1670 || 10iter: 13.0477 sec.\n","イテレーション 580 || Loss: 0.1764 || 10iter: 13.0389 sec.\n","イテレーション 590 || Loss: 0.3166 || 10iter: 12.9865 sec.\n","イテレーション 600 || Loss: 0.1342 || 10iter: 13.0365 sec.\n","イテレーション 610 || Loss: 0.2044 || 10iter: 13.0247 sec.\n","イテレーション 620 || Loss: 0.1196 || 10iter: 13.0516 sec.\n","イテレーション 630 || Loss: 0.1865 || 10iter: 13.0037 sec.\n","イテレーション 640 || Loss: 0.1338 || 10iter: 12.9816 sec.\n","イテレーション 650 || Loss: 0.1791 || 10iter: 13.0344 sec.\n","イテレーション 660 || Loss: 0.1949 || 10iter: 13.0775 sec.\n","イテレーション 670 || Loss: 0.1679 || 10iter: 12.9892 sec.\n","イテレーション 680 || Loss: 0.2229 || 10iter: 13.0782 sec.\n","イテレーション 690 || Loss: 0.1559 || 10iter: 13.0517 sec.\n","イテレーション 700 || Loss: 0.2579 || 10iter: 13.0291 sec.\n","イテレーション 710 || Loss: 0.1342 || 10iter: 13.0176 sec.\n","イテレーション 720 || Loss: 0.0823 || 10iter: 12.9803 sec.\n","イテレーション 730 || Loss: 0.1827 || 10iter: 13.0035 sec.\n","-------------\n","epoch 4 || Epoch_TRAIN_Loss:0.1800 ||Epoch_VAL_Loss:0.0000\n","timer:  259.0352 sec.\n","-------------\n","Epoch 5/30\n","-------------\n","（train）\n","イテレーション 740 || Loss: 0.1415 || 10iter: 10.1633 sec.\n","イテレーション 750 || Loss: 0.1764 || 10iter: 13.0179 sec.\n","イテレーション 760 || Loss: 0.2941 || 10iter: 13.0742 sec.\n","イテレーション 770 || Loss: 0.1499 || 10iter: 13.0414 sec.\n","イテレーション 780 || Loss: 0.1310 || 10iter: 13.0365 sec.\n","イテレーション 790 || Loss: 0.1839 || 10iter: 13.0284 sec.\n","イテレーション 800 || Loss: 0.2061 || 10iter: 12.9377 sec.\n","イテレーション 810 || Loss: 0.1073 || 10iter: 12.9946 sec.\n","イテレーション 820 || Loss: 0.3011 || 10iter: 12.9730 sec.\n","イテレーション 830 || Loss: 0.1030 || 10iter: 12.9753 sec.\n","イテレーション 840 || Loss: 0.1438 || 10iter: 13.0454 sec.\n","イテレーション 850 || Loss: 0.2154 || 10iter: 12.9340 sec.\n","イテレーション 860 || Loss: 0.1053 || 10iter: 12.9890 sec.\n","イテレーション 870 || Loss: 0.1271 || 10iter: 13.0025 sec.\n","イテレーション 880 || Loss: 0.1518 || 10iter: 13.0359 sec.\n","イテレーション 890 || Loss: 0.1537 || 10iter: 12.9421 sec.\n","イテレーション 900 || Loss: 0.1582 || 10iter: 13.0217 sec.\n","イテレーション 910 || Loss: 0.1595 || 10iter: 12.9591 sec.\n","-------------\n","（val）\n","-------------\n","epoch 5 || Epoch_TRAIN_Loss:0.1759 ||Epoch_VAL_Loss:0.2062\n","timer:  342.6604 sec.\n","-------------\n","Epoch 6/30\n","-------------\n","（train）\n","イテレーション 920 || Loss: 0.1710 || 10iter: 5.9294 sec.\n","イテレーション 930 || Loss: 0.1204 || 10iter: 13.0283 sec.\n","イテレーション 940 || Loss: 0.3060 || 10iter: 13.0175 sec.\n","イテレーション 950 || Loss: 0.1150 || 10iter: 12.9729 sec.\n","イテレーション 960 || Loss: 0.2124 || 10iter: 12.9680 sec.\n","イテレーション 970 || Loss: 0.2241 || 10iter: 12.9822 sec.\n","イテレーション 980 || Loss: 0.1968 || 10iter: 12.9870 sec.\n","イテレーション 990 || Loss: 0.1663 || 10iter: 13.0485 sec.\n","イテレーション 1000 || Loss: 0.2121 || 10iter: 12.9583 sec.\n","イテレーション 1010 || Loss: 0.1380 || 10iter: 12.9759 sec.\n","イテレーション 1020 || Loss: 0.2682 || 10iter: 12.9598 sec.\n","イテレーション 1030 || Loss: 0.1515 || 10iter: 13.0283 sec.\n","イテレーション 1040 || Loss: 0.1645 || 10iter: 12.9850 sec.\n","イテレーション 1050 || Loss: 0.1358 || 10iter: 13.0688 sec.\n","イテレーション 1060 || Loss: 0.1509 || 10iter: 13.0753 sec.\n","イテレーション 1070 || Loss: 0.1971 || 10iter: 13.0324 sec.\n","イテレーション 1080 || Loss: 0.1784 || 10iter: 13.0040 sec.\n","イテレーション 1090 || Loss: 0.2292 || 10iter: 12.9373 sec.\n","-------------\n","epoch 6 || Epoch_TRAIN_Loss:0.1774 ||Epoch_VAL_Loss:0.0000\n","timer:  258.5494 sec.\n","-------------\n","Epoch 7/30\n","-------------\n","（train）\n","イテレーション 1100 || Loss: 0.1587 || 10iter: 1.7021 sec.\n","イテレーション 1110 || Loss: 0.1412 || 10iter: 13.0046 sec.\n","イテレーション 1120 || Loss: 0.1192 || 10iter: 13.0220 sec.\n","イテレーション 1130 || Loss: 0.2169 || 10iter: 12.9031 sec.\n","イテレーション 1140 || Loss: 0.1909 || 10iter: 13.0227 sec.\n","イテレーション 1150 || Loss: 0.2931 || 10iter: 13.0462 sec.\n","イテレーション 1160 || Loss: 0.1190 || 10iter: 13.0138 sec.\n","イテレーション 1170 || Loss: 0.3194 || 10iter: 13.0089 sec.\n","イテレーション 1180 || Loss: 0.1971 || 10iter: 13.0953 sec.\n","イテレーション 1190 || Loss: 0.1495 || 10iter: 13.0622 sec.\n","イテレーション 1200 || Loss: 0.1680 || 10iter: 13.1003 sec.\n","イテレーション 1210 || Loss: 0.1469 || 10iter: 13.0680 sec.\n","イテレーション 1220 || Loss: 0.1969 || 10iter: 13.0347 sec.\n","イテレーション 1230 || Loss: 0.1238 || 10iter: 13.0158 sec.\n","イテレーション 1240 || Loss: 0.1881 || 10iter: 12.9905 sec.\n","イテレーション 1250 || Loss: 0.1868 || 10iter: 13.0512 sec.\n","イテレーション 1260 || Loss: 0.1552 || 10iter: 13.0029 sec.\n","イテレーション 1270 || Loss: 0.1214 || 10iter: 13.0075 sec.\n","イテレーション 1280 || Loss: 0.1764 || 10iter: 12.9774 sec.\n","-------------\n","epoch 7 || Epoch_TRAIN_Loss:0.1759 ||Epoch_VAL_Loss:0.0000\n","timer:  259.0173 sec.\n","-------------\n","Epoch 8/30\n","-------------\n","（train）\n","イテレーション 1290 || Loss: 0.1878 || 10iter: 11.5684 sec.\n","イテレーション 1300 || Loss: 0.1000 || 10iter: 13.0358 sec.\n","イテレーション 1310 || Loss: 0.1732 || 10iter: 13.0417 sec.\n","イテレーション 1320 || Loss: 0.2326 || 10iter: 13.0283 sec.\n","イテレーション 1330 || Loss: 0.2298 || 10iter: 13.0204 sec.\n","イテレーション 1340 || Loss: 0.1443 || 10iter: 13.0484 sec.\n","イテレーション 1350 || Loss: 0.1598 || 10iter: 12.9943 sec.\n","イテレーション 1360 || Loss: 0.1642 || 10iter: 13.0984 sec.\n","イテレーション 1370 || Loss: 0.2355 || 10iter: 13.0288 sec.\n","イテレーション 1380 || Loss: 0.1894 || 10iter: 13.0262 sec.\n","イテレーション 1390 || Loss: 0.2512 || 10iter: 13.0119 sec.\n","イテレーション 1400 || Loss: 0.1918 || 10iter: 13.0759 sec.\n","イテレーション 1410 || Loss: 0.1911 || 10iter: 13.0275 sec.\n","イテレーション 1420 || Loss: 0.2048 || 10iter: 13.0632 sec.\n","イテレーション 1430 || Loss: 0.2171 || 10iter: 13.0034 sec.\n","イテレーション 1440 || Loss: 0.1580 || 10iter: 13.0383 sec.\n","イテレーション 1450 || Loss: 0.1581 || 10iter: 12.9778 sec.\n","イテレーション 1460 || Loss: 0.2300 || 10iter: 13.0259 sec.\n","-------------\n","epoch 8 || Epoch_TRAIN_Loss:0.1736 ||Epoch_VAL_Loss:0.0000\n","timer:  259.1400 sec.\n","-------------\n","Epoch 9/30\n","-------------\n","（train）\n","イテレーション 1470 || Loss: 0.1695 || 10iter: 7.3914 sec.\n","イテレーション 1480 || Loss: 0.1292 || 10iter: 13.0055 sec.\n","イテレーション 1490 || Loss: 0.1838 || 10iter: 13.1005 sec.\n","イテレーション 1500 || Loss: 0.1537 || 10iter: 13.0288 sec.\n","イテレーション 1510 || Loss: 0.2047 || 10iter: 12.9818 sec.\n","イテレーション 1520 || Loss: 0.1517 || 10iter: 12.9464 sec.\n","イテレーション 1530 || Loss: 0.2184 || 10iter: 12.9643 sec.\n","イテレーション 1540 || Loss: 0.2294 || 10iter: 13.0601 sec.\n","イテレーション 1550 || Loss: 0.1092 || 10iter: 13.0068 sec.\n","イテレーション 1560 || Loss: 0.1645 || 10iter: 13.0326 sec.\n","イテレーション 1570 || Loss: 0.1679 || 10iter: 13.0212 sec.\n","イテレーション 1580 || Loss: 0.1394 || 10iter: 13.0093 sec.\n","イテレーション 1590 || Loss: 0.2951 || 10iter: 13.0211 sec.\n","イテレーション 1600 || Loss: 0.1726 || 10iter: 13.0402 sec.\n","イテレーション 1610 || Loss: 0.1197 || 10iter: 13.0497 sec.\n","イテレーション 1620 || Loss: 0.1040 || 10iter: 13.0344 sec.\n","イテレーション 1630 || Loss: 0.1461 || 10iter: 12.9981 sec.\n","イテレーション 1640 || Loss: 0.1224 || 10iter: 13.0345 sec.\n","-------------\n","epoch 9 || Epoch_TRAIN_Loss:0.1687 ||Epoch_VAL_Loss:0.0000\n","timer:  258.9368 sec.\n","-------------\n","Epoch 10/30\n","-------------\n","（train）\n","イテレーション 1650 || Loss: 0.1587 || 10iter: 3.1424 sec.\n","イテレーション 1660 || Loss: 0.1736 || 10iter: 12.9757 sec.\n","イテレーション 1670 || Loss: 0.1590 || 10iter: 13.0078 sec.\n","イテレーション 1680 || Loss: 0.1501 || 10iter: 13.0559 sec.\n","イテレーション 1690 || Loss: 0.1869 || 10iter: 13.0539 sec.\n","イテレーション 1700 || Loss: 0.1830 || 10iter: 13.0408 sec.\n","イテレーション 1710 || Loss: 0.2295 || 10iter: 12.9813 sec.\n","イテレーション 1720 || Loss: 0.2143 || 10iter: 12.9975 sec.\n","イテレーション 1730 || Loss: 0.1099 || 10iter: 13.0020 sec.\n","イテレーション 1740 || Loss: 0.1426 || 10iter: 12.9397 sec.\n","イテレーション 1750 || Loss: 0.1516 || 10iter: 13.0032 sec.\n","イテレーション 1760 || Loss: 0.1745 || 10iter: 13.0566 sec.\n","イテレーション 1770 || Loss: 0.1881 || 10iter: 12.9965 sec.\n","イテレーション 1780 || Loss: 0.1722 || 10iter: 13.0619 sec.\n","イテレーション 1790 || Loss: 0.1490 || 10iter: 13.0538 sec.\n","イテレーション 1800 || Loss: 0.1487 || 10iter: 13.0695 sec.\n","イテレーション 1810 || Loss: 0.2469 || 10iter: 13.0311 sec.\n","イテレーション 1820 || Loss: 0.2474 || 10iter: 12.9996 sec.\n","イテレーション 1830 || Loss: 0.2214 || 10iter: 13.0846 sec.\n","-------------\n","（val）\n","-------------\n","epoch 10 || Epoch_TRAIN_Loss:0.1684 ||Epoch_VAL_Loss:0.1955\n","timer:  343.0047 sec.\n","-------------\n","Epoch 11/30\n","-------------\n","（train）\n","イテレーション 1840 || Loss: 0.1741 || 10iter: 13.0314 sec.\n","イテレーション 1850 || Loss: 0.1595 || 10iter: 13.0929 sec.\n","イテレーション 1860 || Loss: 0.1492 || 10iter: 13.0422 sec.\n","イテレーション 1870 || Loss: 0.1096 || 10iter: 13.0851 sec.\n","イテレーション 1880 || Loss: 0.2083 || 10iter: 12.9946 sec.\n","イテレーション 1890 || Loss: 0.1263 || 10iter: 12.9975 sec.\n","イテレーション 1900 || Loss: 0.1074 || 10iter: 13.0037 sec.\n","イテレーション 1910 || Loss: 0.2132 || 10iter: 13.0755 sec.\n","イテレーション 1920 || Loss: 0.1366 || 10iter: 13.0210 sec.\n","イテレーション 1930 || Loss: 0.1248 || 10iter: 13.0662 sec.\n","イテレーション 1940 || Loss: 0.2158 || 10iter: 13.0270 sec.\n","イテレーション 1950 || Loss: 0.2295 || 10iter: 13.0288 sec.\n","イテレーション 1960 || Loss: 0.1209 || 10iter: 13.0167 sec.\n","イテレーション 1970 || Loss: 0.1488 || 10iter: 13.0164 sec.\n","イテレーション 1980 || Loss: 0.1855 || 10iter: 12.9403 sec.\n","イテレーション 1990 || Loss: 0.1379 || 10iter: 12.9463 sec.\n","イテレーション 2000 || Loss: 0.0759 || 10iter: 12.9415 sec.\n","イテレーション 2010 || Loss: 0.1761 || 10iter: 12.9390 sec.\n","-------------\n","epoch 11 || Epoch_TRAIN_Loss:0.1627 ||Epoch_VAL_Loss:0.0000\n","timer:  258.8831 sec.\n","-------------\n","Epoch 12/30\n","-------------\n","（train）\n","イテレーション 2020 || Loss: 0.1371 || 10iter: 8.7894 sec.\n","イテレーション 2030 || Loss: 0.1520 || 10iter: 13.0380 sec.\n","イテレーション 2040 || Loss: 0.1285 || 10iter: 12.9346 sec.\n","イテレーション 2050 || Loss: 0.1519 || 10iter: 13.0177 sec.\n","イテレーション 2060 || Loss: 0.0702 || 10iter: 12.9683 sec.\n","イテレーション 2070 || Loss: 0.2298 || 10iter: 13.0983 sec.\n","イテレーション 2080 || Loss: 0.1161 || 10iter: 13.0134 sec.\n","イテレーション 2090 || Loss: 0.1460 || 10iter: 12.9966 sec.\n","イテレーション 2100 || Loss: 0.1387 || 10iter: 12.9710 sec.\n","イテレーション 2110 || Loss: 0.2288 || 10iter: 13.0351 sec.\n","イテレーション 2120 || Loss: 0.1288 || 10iter: 12.9857 sec.\n","イテレーション 2130 || Loss: 0.1275 || 10iter: 12.9815 sec.\n","イテレーション 2140 || Loss: 0.1810 || 10iter: 13.0087 sec.\n","イテレーション 2150 || Loss: 0.1583 || 10iter: 13.0258 sec.\n","イテレーション 2160 || Loss: 0.1961 || 10iter: 13.0401 sec.\n","イテレーション 2170 || Loss: 0.1537 || 10iter: 13.0933 sec.\n","イテレーション 2180 || Loss: 0.1651 || 10iter: 12.9809 sec.\n","イテレーション 2190 || Loss: 0.1536 || 10iter: 13.0560 sec.\n","-------------\n","epoch 12 || Epoch_TRAIN_Loss:0.1600 ||Epoch_VAL_Loss:0.0000\n","timer:  258.9033 sec.\n","-------------\n","Epoch 13/30\n","-------------\n","（train）\n","イテレーション 2200 || Loss: 0.2172 || 10iter: 4.5278 sec.\n","イテレーション 2210 || Loss: 0.1318 || 10iter: 13.0517 sec.\n","イテレーション 2220 || Loss: 0.0986 || 10iter: 13.0317 sec.\n","イテレーション 2230 || Loss: 0.2181 || 10iter: 13.0327 sec.\n","イテレーション 2240 || Loss: 0.1679 || 10iter: 13.0430 sec.\n","イテレーション 2250 || Loss: 0.1124 || 10iter: 12.9919 sec.\n","イテレーション 2260 || Loss: 0.1611 || 10iter: 13.0209 sec.\n","イテレーション 2270 || Loss: 0.2183 || 10iter: 13.0144 sec.\n","イテレーション 2280 || Loss: 0.1790 || 10iter: 13.0006 sec.\n","イテレーション 2290 || Loss: 0.1316 || 10iter: 13.0023 sec.\n","イテレーション 2300 || Loss: 0.2611 || 10iter: 13.0325 sec.\n","イテレーション 2310 || Loss: 0.1851 || 10iter: 12.9876 sec.\n","イテレーション 2320 || Loss: 0.1807 || 10iter: 13.0590 sec.\n","イテレーション 2330 || Loss: 0.1154 || 10iter: 12.9635 sec.\n","イテレーション 2340 || Loss: 0.1466 || 10iter: 12.9595 sec.\n","イテレーション 2350 || Loss: 0.1950 || 10iter: 13.0306 sec.\n","イテレーション 2360 || Loss: 0.1475 || 10iter: 13.0738 sec.\n","イテレーション 2370 || Loss: 0.1985 || 10iter: 13.0816 sec.\n","-------------\n","epoch 13 || Epoch_TRAIN_Loss:0.1613 ||Epoch_VAL_Loss:0.0000\n","timer:  258.9396 sec.\n","-------------\n","Epoch 14/30\n","-------------\n","（train）\n","イテレーション 2380 || Loss: 0.1180 || 10iter: 0.2810 sec.\n","イテレーション 2390 || Loss: 0.1968 || 10iter: 13.0291 sec.\n","イテレーション 2400 || Loss: 0.1141 || 10iter: 12.9969 sec.\n","イテレーション 2410 || Loss: 0.1577 || 10iter: 13.1373 sec.\n","イテレーション 2420 || Loss: 0.1753 || 10iter: 13.0574 sec.\n","イテレーション 2430 || Loss: 0.1318 || 10iter: 12.9918 sec.\n","イテレーション 2440 || Loss: 0.1143 || 10iter: 13.0419 sec.\n","イテレーション 2450 || Loss: 0.1546 || 10iter: 13.0834 sec.\n","イテレーション 2460 || Loss: 0.1638 || 10iter: 13.0745 sec.\n","イテレーション 2470 || Loss: 0.1213 || 10iter: 13.0151 sec.\n","イテレーション 2480 || Loss: 0.1312 || 10iter: 13.0509 sec.\n","イテレーション 2490 || Loss: 0.1864 || 10iter: 13.0655 sec.\n","イテレーション 2500 || Loss: 0.1142 || 10iter: 13.0659 sec.\n","イテレーション 2510 || Loss: 0.1725 || 10iter: 13.0459 sec.\n","イテレーション 2520 || Loss: 0.1718 || 10iter: 13.0066 sec.\n","イテレーション 2530 || Loss: 0.2205 || 10iter: 13.0359 sec.\n","イテレーション 2540 || Loss: 0.1442 || 10iter: 13.0967 sec.\n","イテレーション 2550 || Loss: 0.1878 || 10iter: 13.0858 sec.\n","イテレーション 2560 || Loss: 0.1307 || 10iter: 13.0635 sec.\n","-------------\n","epoch 14 || Epoch_TRAIN_Loss:0.1580 ||Epoch_VAL_Loss:0.0000\n","timer:  259.4842 sec.\n","-------------\n","Epoch 15/30\n","-------------\n","（train）\n","イテレーション 2570 || Loss: 0.1692 || 10iter: 10.1611 sec.\n","イテレーション 2580 || Loss: 0.1361 || 10iter: 13.0365 sec.\n","イテレーション 2590 || Loss: 0.1319 || 10iter: 12.9937 sec.\n","イテレーション 2600 || Loss: 0.1751 || 10iter: 12.9796 sec.\n","イテレーション 2610 || Loss: 0.1135 || 10iter: 12.9921 sec.\n","イテレーション 2620 || Loss: 0.1084 || 10iter: 13.0841 sec.\n","イテレーション 2630 || Loss: 0.1382 || 10iter: 12.9614 sec.\n","イテレーション 2640 || Loss: 0.2159 || 10iter: 13.0164 sec.\n","イテレーション 2650 || Loss: 0.1558 || 10iter: 13.0206 sec.\n","イテレーション 2660 || Loss: 0.1282 || 10iter: 13.0818 sec.\n","イテレーション 2670 || Loss: 0.1410 || 10iter: 13.0060 sec.\n","イテレーション 2680 || Loss: 0.1458 || 10iter: 13.0961 sec.\n","イテレーション 2690 || Loss: 0.1852 || 10iter: 12.9936 sec.\n","イテレーション 2700 || Loss: 0.1190 || 10iter: 13.0114 sec.\n","イテレーション 2710 || Loss: 0.1122 || 10iter: 13.0603 sec.\n","イテレーション 2720 || Loss: 0.1578 || 10iter: 13.0480 sec.\n","イテレーション 2730 || Loss: 0.1803 || 10iter: 12.9939 sec.\n","イテレーション 2740 || Loss: 0.1289 || 10iter: 13.1103 sec.\n","-------------\n","（val）\n","-------------\n","epoch 15 || Epoch_TRAIN_Loss:0.1618 ||Epoch_VAL_Loss:0.1889\n","timer:  342.9045 sec.\n","-------------\n","Epoch 16/30\n","-------------\n","（train）\n","イテレーション 2750 || Loss: 0.1814 || 10iter: 5.9386 sec.\n","イテレーション 2760 || Loss: 0.1416 || 10iter: 13.0031 sec.\n","イテレーション 2770 || Loss: 0.2177 || 10iter: 13.0207 sec.\n","イテレーション 2780 || Loss: 0.2255 || 10iter: 13.0355 sec.\n","イテレーション 2790 || Loss: 0.1201 || 10iter: 13.0209 sec.\n","イテレーション 2800 || Loss: 0.2220 || 10iter: 13.0274 sec.\n","イテレーション 2810 || Loss: 0.1946 || 10iter: 12.9957 sec.\n","イテレーション 2820 || Loss: 0.1624 || 10iter: 13.0238 sec.\n","イテレーション 2830 || Loss: 0.1809 || 10iter: 12.9944 sec.\n","イテレーション 2840 || Loss: 0.1444 || 10iter: 12.9685 sec.\n","イテレーション 2850 || Loss: 0.1726 || 10iter: 12.9947 sec.\n","イテレーション 2860 || Loss: 0.2360 || 10iter: 13.0417 sec.\n","イテレーション 2870 || Loss: 0.2109 || 10iter: 13.0017 sec.\n","イテレーション 2880 || Loss: 0.1131 || 10iter: 12.9644 sec.\n","イテレーション 2890 || Loss: 0.1868 || 10iter: 13.1011 sec.\n","イテレーション 2900 || Loss: 0.1811 || 10iter: 13.0824 sec.\n","イテレーション 2910 || Loss: 0.1879 || 10iter: 13.0782 sec.\n","イテレーション 2920 || Loss: 0.1809 || 10iter: 12.9583 sec.\n","-------------\n","epoch 16 || Epoch_TRAIN_Loss:0.1583 ||Epoch_VAL_Loss:0.0000\n","timer:  258.9359 sec.\n","-------------\n","Epoch 17/30\n","-------------\n","（train）\n","イテレーション 2930 || Loss: 0.1249 || 10iter: 1.7162 sec.\n","イテレーション 2940 || Loss: 0.1971 || 10iter: 13.0338 sec.\n","イテレーション 2950 || Loss: 0.1412 || 10iter: 13.0534 sec.\n","イテレーション 2960 || Loss: 0.1481 || 10iter: 13.0163 sec.\n","イテレーション 2970 || Loss: 0.1764 || 10iter: 12.9633 sec.\n","イテレーション 2980 || Loss: 0.2288 || 10iter: 13.0633 sec.\n","イテレーション 2990 || Loss: 0.1354 || 10iter: 13.0729 sec.\n","イテレーション 3000 || Loss: 0.2358 || 10iter: 13.0483 sec.\n","イテレーション 3010 || Loss: 0.0979 || 10iter: 13.0152 sec.\n","イテレーション 3020 || Loss: 0.1466 || 10iter: 13.0237 sec.\n","イテレーション 3030 || Loss: 0.0864 || 10iter: 12.9953 sec.\n","イテレーション 3040 || Loss: 0.0966 || 10iter: 13.0302 sec.\n","イテレーション 3050 || Loss: 0.1363 || 10iter: 13.0722 sec.\n","イテレーション 3060 || Loss: 0.1535 || 10iter: 13.0655 sec.\n","イテレーション 3070 || Loss: 0.1224 || 10iter: 13.0616 sec.\n","イテレーション 3080 || Loss: 0.1844 || 10iter: 13.0356 sec.\n","イテレーション 3090 || Loss: 0.1773 || 10iter: 12.9888 sec.\n","イテレーション 3100 || Loss: 0.1188 || 10iter: 13.0977 sec.\n","イテレーション 3110 || Loss: 0.1420 || 10iter: 12.9821 sec.\n","-------------\n","epoch 17 || Epoch_TRAIN_Loss:0.1579 ||Epoch_VAL_Loss:0.0000\n","timer:  259.2070 sec.\n","-------------\n","Epoch 18/30\n","-------------\n","（train）\n","イテレーション 3120 || Loss: 0.1276 || 10iter: 11.6159 sec.\n","イテレーション 3130 || Loss: 0.1666 || 10iter: 13.0259 sec.\n","イテレーション 3140 || Loss: 0.1102 || 10iter: 13.0670 sec.\n","イテレーション 3150 || Loss: 0.2468 || 10iter: 13.0335 sec.\n","イテレーション 3160 || Loss: 0.1030 || 10iter: 12.9686 sec.\n","イテレーション 3170 || Loss: 0.2111 || 10iter: 12.9794 sec.\n","イテレーション 3180 || Loss: 0.1048 || 10iter: 12.9848 sec.\n","イテレーション 3190 || Loss: 0.1563 || 10iter: 13.0424 sec.\n","イテレーション 3200 || Loss: 0.1895 || 10iter: 13.0152 sec.\n","イテレーション 3210 || Loss: 0.1113 || 10iter: 13.0439 sec.\n","イテレーション 3220 || Loss: 0.1937 || 10iter: 12.9815 sec.\n","イテレーション 3230 || Loss: 0.2273 || 10iter: 12.9954 sec.\n","イテレーション 3240 || Loss: 0.1471 || 10iter: 13.0708 sec.\n","イテレーション 3250 || Loss: 0.1396 || 10iter: 13.0733 sec.\n","イテレーション 3260 || Loss: 0.1593 || 10iter: 13.0395 sec.\n","イテレーション 3270 || Loss: 0.2080 || 10iter: 13.0373 sec.\n","イテレーション 3280 || Loss: 0.1988 || 10iter: 13.0083 sec.\n","イテレーション 3290 || Loss: 0.2199 || 10iter: 13.1010 sec.\n","-------------\n","epoch 18 || Epoch_TRAIN_Loss:0.1558 ||Epoch_VAL_Loss:0.0000\n","timer:  259.1339 sec.\n","-------------\n","Epoch 19/30\n","-------------\n","（train）\n","イテレーション 3300 || Loss: 0.1276 || 10iter: 7.4113 sec.\n","イテレーション 3310 || Loss: 0.1074 || 10iter: 13.0555 sec.\n","イテレーション 3320 || Loss: 0.1484 || 10iter: 13.0465 sec.\n","イテレーション 3330 || Loss: 0.1778 || 10iter: 13.1037 sec.\n","イテレーション 3340 || Loss: 0.1796 || 10iter: 13.0542 sec.\n","イテレーション 3350 || Loss: 0.1593 || 10iter: 13.0510 sec.\n","イテレーション 3360 || Loss: 0.2431 || 10iter: 13.0434 sec.\n","イテレーション 3370 || Loss: 0.1274 || 10iter: 13.0949 sec.\n","イテレーション 3380 || Loss: 0.1324 || 10iter: 13.0675 sec.\n","イテレーション 3390 || Loss: 0.1513 || 10iter: 12.9955 sec.\n","イテレーション 3400 || Loss: 0.1581 || 10iter: 13.0806 sec.\n","イテレーション 3410 || Loss: 0.1283 || 10iter: 13.0476 sec.\n","イテレーション 3420 || Loss: 0.1608 || 10iter: 13.0284 sec.\n","イテレーション 3430 || Loss: 0.1432 || 10iter: 13.0106 sec.\n","イテレーション 3440 || Loss: 0.1403 || 10iter: 13.0369 sec.\n","イテレーション 3450 || Loss: 0.1476 || 10iter: 13.1074 sec.\n","イテレーション 3460 || Loss: 0.1079 || 10iter: 13.0489 sec.\n","イテレーション 3470 || Loss: 0.1627 || 10iter: 13.0159 sec.\n","-------------\n","epoch 19 || Epoch_TRAIN_Loss:0.1549 ||Epoch_VAL_Loss:0.0000\n","timer:  259.5216 sec.\n","-------------\n","Epoch 20/30\n","-------------\n","（train）\n","イテレーション 3480 || Loss: 0.1159 || 10iter: 3.1376 sec.\n","イテレーション 3490 || Loss: 0.1467 || 10iter: 13.0324 sec.\n","イテレーション 3500 || Loss: 0.1754 || 10iter: 12.9837 sec.\n","イテレーション 3510 || Loss: 0.1285 || 10iter: 12.9902 sec.\n","イテレーション 3520 || Loss: 0.0929 || 10iter: 13.0422 sec.\n","イテレーション 3530 || Loss: 0.1330 || 10iter: 13.0494 sec.\n","イテレーション 3540 || Loss: 0.2207 || 10iter: 13.0709 sec.\n","イテレーション 3550 || Loss: 0.1627 || 10iter: 13.0416 sec.\n","イテレーション 3560 || Loss: 0.1057 || 10iter: 13.0040 sec.\n","イテレーション 3570 || Loss: 0.2254 || 10iter: 13.0039 sec.\n","イテレーション 3580 || Loss: 0.1175 || 10iter: 13.0169 sec.\n","イテレーション 3590 || Loss: 0.1730 || 10iter: 13.0234 sec.\n","イテレーション 3600 || Loss: 0.1128 || 10iter: 13.0091 sec.\n","イテレーション 3610 || Loss: 0.1805 || 10iter: 12.9893 sec.\n","イテレーション 3620 || Loss: 0.1332 || 10iter: 13.0188 sec.\n","イテレーション 3630 || Loss: 0.1217 || 10iter: 12.9880 sec.\n","イテレーション 3640 || Loss: 0.1267 || 10iter: 13.0770 sec.\n","イテレーション 3650 || Loss: 0.0706 || 10iter: 13.0620 sec.\n","イテレーション 3660 || Loss: 0.1543 || 10iter: 13.0019 sec.\n","-------------\n","（val）\n","-------------\n","epoch 20 || Epoch_TRAIN_Loss:0.1540 ||Epoch_VAL_Loss:0.1835\n","timer:  342.6455 sec.\n","-------------\n","Epoch 21/30\n","-------------\n","（train）\n","イテレーション 3670 || Loss: 0.1586 || 10iter: 13.0051 sec.\n","イテレーション 3680 || Loss: 0.1882 || 10iter: 13.0077 sec.\n","イテレーション 3690 || Loss: 0.1074 || 10iter: 12.9665 sec.\n","イテレーション 3700 || Loss: 0.0841 || 10iter: 12.9897 sec.\n","イテレーション 3710 || Loss: 0.0691 || 10iter: 13.0695 sec.\n","イテレーション 3720 || Loss: 0.2391 || 10iter: 13.0165 sec.\n","イテレーション 3730 || Loss: 0.2779 || 10iter: 13.0286 sec.\n","イテレーション 3740 || Loss: 0.1588 || 10iter: 13.0385 sec.\n","イテレーション 3750 || Loss: 0.1208 || 10iter: 13.0184 sec.\n","イテレーション 3760 || Loss: 0.1506 || 10iter: 13.0841 sec.\n","イテレーション 3770 || Loss: 0.1277 || 10iter: 12.9667 sec.\n","イテレーション 3780 || Loss: 0.2240 || 10iter: 13.0919 sec.\n","イテレーション 3790 || Loss: 0.1624 || 10iter: 12.9652 sec.\n","イテレーション 3800 || Loss: 0.1515 || 10iter: 13.0388 sec.\n","イテレーション 3810 || Loss: 0.1889 || 10iter: 13.0552 sec.\n","イテレーション 3820 || Loss: 0.1804 || 10iter: 13.0720 sec.\n","イテレーション 3830 || Loss: 0.1506 || 10iter: 13.0240 sec.\n","イテレーション 3840 || Loss: 0.1451 || 10iter: 12.9867 sec.\n","-------------\n","epoch 21 || Epoch_TRAIN_Loss:0.1520 ||Epoch_VAL_Loss:0.0000\n","timer:  259.0155 sec.\n","-------------\n","Epoch 22/30\n","-------------\n","（train）\n","イテレーション 3850 || Loss: 0.1312 || 10iter: 8.8358 sec.\n","イテレーション 3860 || Loss: 0.2672 || 10iter: 13.0795 sec.\n","イテレーション 3870 || Loss: 0.1939 || 10iter: 13.0883 sec.\n","イテレーション 3880 || Loss: 0.0921 || 10iter: 13.0961 sec.\n","イテレーション 3890 || Loss: 0.1548 || 10iter: 13.0685 sec.\n","イテレーション 3900 || Loss: 0.1658 || 10iter: 13.0386 sec.\n","イテレーション 3910 || Loss: 0.1189 || 10iter: 13.0275 sec.\n","イテレーション 3920 || Loss: 0.1219 || 10iter: 13.0456 sec.\n","イテレーション 3930 || Loss: 0.2025 || 10iter: 13.1256 sec.\n","イテレーション 3940 || Loss: 0.1246 || 10iter: 13.1229 sec.\n","イテレーション 3950 || Loss: 0.1008 || 10iter: 13.0905 sec.\n","イテレーション 3960 || Loss: 0.1777 || 10iter: 13.0223 sec.\n","イテレーション 3970 || Loss: 0.1846 || 10iter: 13.0505 sec.\n","イテレーション 3980 || Loss: 0.1006 || 10iter: 13.0953 sec.\n","イテレーション 3990 || Loss: 0.2232 || 10iter: 13.0621 sec.\n","イテレーション 4000 || Loss: 0.1846 || 10iter: 13.0988 sec.\n","イテレーション 4010 || Loss: 0.1911 || 10iter: 13.0500 sec.\n","イテレーション 4020 || Loss: 0.1702 || 10iter: 13.1081 sec.\n","-------------\n","epoch 22 || Epoch_TRAIN_Loss:0.1505 ||Epoch_VAL_Loss:0.0000\n","timer:  259.9222 sec.\n","-------------\n","Epoch 23/30\n","-------------\n","（train）\n","イテレーション 4030 || Loss: 0.2261 || 10iter: 4.5791 sec.\n","イテレーション 4040 || Loss: 0.1207 || 10iter: 13.0854 sec.\n","イテレーション 4050 || Loss: 0.1696 || 10iter: 13.0122 sec.\n","イテレーション 4060 || Loss: 0.1397 || 10iter: 13.0923 sec.\n","イテレーション 4070 || Loss: 0.1142 || 10iter: 13.0647 sec.\n","イテレーション 4080 || Loss: 0.1222 || 10iter: 13.1421 sec.\n","イテレーション 4090 || Loss: 0.1775 || 10iter: 13.0931 sec.\n","イテレーション 4100 || Loss: 0.1340 || 10iter: 13.1009 sec.\n","イテレーション 4110 || Loss: 0.1364 || 10iter: 13.0153 sec.\n","イテレーション 4120 || Loss: 0.1756 || 10iter: 13.0726 sec.\n","イテレーション 4130 || Loss: 0.1575 || 10iter: 13.0668 sec.\n","イテレーション 4140 || Loss: 0.1287 || 10iter: 13.0920 sec.\n","イテレーション 4150 || Loss: 0.2229 || 10iter: 13.1371 sec.\n","イテレーション 4160 || Loss: 0.1192 || 10iter: 13.0434 sec.\n","イテレーション 4170 || Loss: 0.2509 || 10iter: 13.0954 sec.\n","イテレーション 4180 || Loss: 0.1977 || 10iter: 13.0792 sec.\n","イテレーション 4190 || Loss: 0.1726 || 10iter: 13.0944 sec.\n","イテレーション 4200 || Loss: 0.2263 || 10iter: 13.1129 sec.\n","-------------\n","epoch 23 || Epoch_TRAIN_Loss:0.1532 ||Epoch_VAL_Loss:0.0000\n","timer:  260.1397 sec.\n","-------------\n","Epoch 24/30\n","-------------\n","（train）\n","イテレーション 4210 || Loss: 0.1788 || 10iter: 0.3240 sec.\n","イテレーション 4220 || Loss: 0.1804 || 10iter: 13.1243 sec.\n","イテレーション 4230 || Loss: 0.0893 || 10iter: 13.0401 sec.\n","イテレーション 4240 || Loss: 0.2236 || 10iter: 13.1180 sec.\n","イテレーション 4250 || Loss: 0.1167 || 10iter: 13.0886 sec.\n","イテレーション 4260 || Loss: 0.1746 || 10iter: 13.0838 sec.\n","イテレーション 4270 || Loss: 0.2498 || 10iter: 13.1004 sec.\n","イテレーション 4280 || Loss: 0.1333 || 10iter: 13.0836 sec.\n","イテレーション 4290 || Loss: 0.1442 || 10iter: 13.0890 sec.\n","イテレーション 4300 || Loss: 0.1251 || 10iter: 13.1411 sec.\n","イテレーション 4310 || Loss: 0.1343 || 10iter: 13.1169 sec.\n","イテレーション 4320 || Loss: 0.0939 || 10iter: 13.0361 sec.\n","イテレーション 4330 || Loss: 0.1226 || 10iter: 13.0728 sec.\n","イテレーション 4340 || Loss: 0.1380 || 10iter: 13.0388 sec.\n","イテレーション 4350 || Loss: 0.1023 || 10iter: 13.0957 sec.\n","イテレーション 4360 || Loss: 0.1251 || 10iter: 13.0964 sec.\n","イテレーション 4370 || Loss: 0.2044 || 10iter: 13.0489 sec.\n","イテレーション 4380 || Loss: 0.2381 || 10iter: 13.0944 sec.\n","イテレーション 4390 || Loss: 0.1880 || 10iter: 13.0806 sec.\n","-------------\n","epoch 24 || Epoch_TRAIN_Loss:0.1501 ||Epoch_VAL_Loss:0.0000\n","timer:  260.1353 sec.\n","-------------\n","Epoch 25/30\n","-------------\n","（train）\n","イテレーション 4400 || Loss: 0.1482 || 10iter: 10.3122 sec.\n","イテレーション 4410 || Loss: 0.1426 || 10iter: 13.0694 sec.\n","イテレーション 4420 || Loss: 0.1285 || 10iter: 13.0662 sec.\n","イテレーション 4430 || Loss: 0.0967 || 10iter: 13.1021 sec.\n","イテレーション 4440 || Loss: 0.1788 || 10iter: 13.1260 sec.\n","イテレーション 4450 || Loss: 0.1130 || 10iter: 13.1177 sec.\n","イテレーション 4460 || Loss: 0.2505 || 10iter: 13.1111 sec.\n","イテレーション 4470 || Loss: 0.1436 || 10iter: 13.0767 sec.\n","イテレーション 4480 || Loss: 0.1831 || 10iter: 13.0383 sec.\n","イテレーション 4490 || Loss: 0.1004 || 10iter: 13.1201 sec.\n","イテレーション 4500 || Loss: 0.0760 || 10iter: 13.1369 sec.\n","イテレーション 4510 || Loss: 0.1910 || 10iter: 13.1045 sec.\n","イテレーション 4520 || Loss: 0.1192 || 10iter: 13.1109 sec.\n","イテレーション 4530 || Loss: 0.1854 || 10iter: 13.0585 sec.\n","イテレーション 4540 || Loss: 0.1440 || 10iter: 13.1533 sec.\n","イテレーション 4550 || Loss: 0.1604 || 10iter: 13.0820 sec.\n","イテレーション 4560 || Loss: 0.2012 || 10iter: 13.1156 sec.\n","イテレーション 4570 || Loss: 0.1243 || 10iter: 13.1579 sec.\n","-------------\n","（val）\n","-------------\n","epoch 25 || Epoch_TRAIN_Loss:0.1488 ||Epoch_VAL_Loss:0.1772\n","timer:  344.8167 sec.\n","-------------\n","Epoch 26/30\n","-------------\n","（train）\n","イテレーション 4580 || Loss: 0.1193 || 10iter: 5.9895 sec.\n","イテレーション 4590 || Loss: 0.1484 || 10iter: 13.0982 sec.\n","イテレーション 4600 || Loss: 0.2401 || 10iter: 13.1014 sec.\n","イテレーション 4610 || Loss: 0.1515 || 10iter: 13.1095 sec.\n","イテレーション 4620 || Loss: 0.1143 || 10iter: 13.1488 sec.\n","イテレーション 4630 || Loss: 0.1748 || 10iter: 13.0713 sec.\n","イテレーション 4640 || Loss: 0.1330 || 10iter: 13.1141 sec.\n","イテレーション 4650 || Loss: 0.1154 || 10iter: 13.1364 sec.\n","イテレーション 4660 || Loss: 0.1342 || 10iter: 13.1154 sec.\n","イテレーション 4670 || Loss: 0.1009 || 10iter: 13.0782 sec.\n","イテレーション 4680 || Loss: 0.0901 || 10iter: 13.1090 sec.\n","イテレーション 4690 || Loss: 0.1678 || 10iter: 13.1550 sec.\n","イテレーション 4700 || Loss: 0.1475 || 10iter: 13.1437 sec.\n","イテレーション 4710 || Loss: 0.2076 || 10iter: 13.1119 sec.\n","イテレーション 4720 || Loss: 0.1638 || 10iter: 13.1082 sec.\n","イテレーション 4730 || Loss: 0.1262 || 10iter: 13.0790 sec.\n","イテレーション 4740 || Loss: 0.1270 || 10iter: 13.0647 sec.\n","イテレーション 4750 || Loss: 0.1006 || 10iter: 13.1108 sec.\n","-------------\n","epoch 26 || Epoch_TRAIN_Loss:0.1441 ||Epoch_VAL_Loss:0.0000\n","timer:  260.5041 sec.\n","-------------\n","Epoch 27/30\n","-------------\n","（train）\n","イテレーション 4760 || Loss: 0.1732 || 10iter: 1.7191 sec.\n","イテレーション 4770 || Loss: 0.1799 || 10iter: 13.1723 sec.\n","イテレーション 4780 || Loss: 0.1038 || 10iter: 13.0950 sec.\n","イテレーション 4790 || Loss: 0.1433 || 10iter: 13.0591 sec.\n","イテレーション 4800 || Loss: 0.1630 || 10iter: 13.1062 sec.\n","イテレーション 4810 || Loss: 0.1106 || 10iter: 13.0935 sec.\n","イテレーション 4820 || Loss: 0.1077 || 10iter: 13.1133 sec.\n","イテレーション 4830 || Loss: 0.1528 || 10iter: 13.0679 sec.\n","イテレーション 4840 || Loss: 0.1267 || 10iter: 13.1584 sec.\n","イテレーション 4850 || Loss: 0.1748 || 10iter: 13.1017 sec.\n","イテレーション 4860 || Loss: 0.1430 || 10iter: 13.0854 sec.\n","イテレーション 4870 || Loss: 0.1631 || 10iter: 12.9960 sec.\n","イテレーション 4880 || Loss: 0.1452 || 10iter: 13.0205 sec.\n","イテレーション 4890 || Loss: 0.1437 || 10iter: 13.0589 sec.\n","イテレーション 4900 || Loss: 0.2047 || 10iter: 13.1039 sec.\n","イテレーション 4910 || Loss: 0.1680 || 10iter: 13.1004 sec.\n","イテレーション 4920 || Loss: 0.0817 || 10iter: 13.1435 sec.\n","イテレーション 4930 || Loss: 0.1557 || 10iter: 13.0703 sec.\n","イテレーション 4940 || Loss: 0.1160 || 10iter: 13.1347 sec.\n","-------------\n","epoch 27 || Epoch_TRAIN_Loss:0.1418 ||Epoch_VAL_Loss:0.0000\n","timer:  260.2474 sec.\n","-------------\n","Epoch 28/30\n","-------------\n","（train）\n","イテレーション 4950 || Loss: 0.1597 || 10iter: 11.6329 sec.\n","イテレーション 4960 || Loss: 0.1559 || 10iter: 13.1088 sec.\n","イテレーション 4970 || Loss: 0.2572 || 10iter: 13.0766 sec.\n","イテレーション 4980 || Loss: 0.1435 || 10iter: 13.0672 sec.\n","イテレーション 4990 || Loss: 0.2548 || 10iter: 13.1216 sec.\n","イテレーション 5000 || Loss: 0.1691 || 10iter: 13.1256 sec.\n","イテレーション 5010 || Loss: 0.1291 || 10iter: 12.9995 sec.\n","イテレーション 5020 || Loss: 0.1087 || 10iter: 13.0826 sec.\n","イテレーション 5030 || Loss: 0.1550 || 10iter: 13.0700 sec.\n","イテレーション 5040 || Loss: 0.1108 || 10iter: 13.0017 sec.\n","イテレーション 5050 || Loss: 0.1019 || 10iter: 13.0570 sec.\n","イテレーション 5060 || Loss: 0.0829 || 10iter: 13.0041 sec.\n","イテレーション 5070 || Loss: 0.0874 || 10iter: 13.0483 sec.\n","イテレーション 5080 || Loss: 0.1414 || 10iter: 13.0388 sec.\n","イテレーション 5090 || Loss: 0.1189 || 10iter: 13.0499 sec.\n","イテレーション 5100 || Loss: 0.1872 || 10iter: 13.0665 sec.\n","イテレーション 5110 || Loss: 0.1453 || 10iter: 13.0203 sec.\n","イテレーション 5120 || Loss: 0.1216 || 10iter: 13.0472 sec.\n","-------------\n","epoch 28 || Epoch_TRAIN_Loss:0.1428 ||Epoch_VAL_Loss:0.0000\n","timer:  259.6279 sec.\n","-------------\n","Epoch 29/30\n","-------------\n","（train）\n","イテレーション 5130 || Loss: 0.1496 || 10iter: 7.3615 sec.\n","イテレーション 5140 || Loss: 0.1694 || 10iter: 13.0744 sec.\n","イテレーション 5150 || Loss: 0.1438 || 10iter: 12.9802 sec.\n","イテレーション 5160 || Loss: 0.1219 || 10iter: 13.0537 sec.\n","イテレーション 5170 || Loss: 0.1891 || 10iter: 13.0686 sec.\n","イテレーション 5180 || Loss: 0.2043 || 10iter: 13.0692 sec.\n","イテレーション 5190 || Loss: 0.1481 || 10iter: 13.0280 sec.\n","イテレーション 5200 || Loss: 0.1263 || 10iter: 13.0616 sec.\n","イテレーション 5210 || Loss: 0.1286 || 10iter: 13.0701 sec.\n","イテレーション 5220 || Loss: 0.1064 || 10iter: 13.0413 sec.\n","イテレーション 5230 || Loss: 0.1049 || 10iter: 13.0250 sec.\n","イテレーション 5240 || Loss: 0.1641 || 10iter: 13.0785 sec.\n","イテレーション 5250 || Loss: 0.1085 || 10iter: 13.0520 sec.\n","イテレーション 5260 || Loss: 0.1654 || 10iter: 13.0053 sec.\n","イテレーション 5270 || Loss: 0.1645 || 10iter: 13.0734 sec.\n","イテレーション 5280 || Loss: 0.1601 || 10iter: 12.9182 sec.\n","イテレーション 5290 || Loss: 0.1587 || 10iter: 12.9189 sec.\n","イテレーション 5300 || Loss: 0.1378 || 10iter: 13.0203 sec.\n","-------------\n","epoch 29 || Epoch_TRAIN_Loss:0.1429 ||Epoch_VAL_Loss:0.0000\n","timer:  259.0568 sec.\n","-------------\n","Epoch 30/30\n","-------------\n","（train）\n","イテレーション 5310 || Loss: 0.1268 || 10iter: 3.1019 sec.\n","イテレーション 5320 || Loss: 0.1058 || 10iter: 13.0109 sec.\n","イテレーション 5330 || Loss: 0.1407 || 10iter: 13.0115 sec.\n","イテレーション 5340 || Loss: 0.1890 || 10iter: 13.0031 sec.\n","イテレーション 5350 || Loss: 0.1418 || 10iter: 13.0954 sec.\n","イテレーション 5360 || Loss: 0.1827 || 10iter: 13.0175 sec.\n","イテレーション 5370 || Loss: 0.1380 || 10iter: 12.9928 sec.\n","イテレーション 5380 || Loss: 0.1713 || 10iter: 13.0711 sec.\n","イテレーション 5390 || Loss: 0.1128 || 10iter: 13.0383 sec.\n","イテレーション 5400 || Loss: 0.1932 || 10iter: 12.9867 sec.\n","イテレーション 5410 || Loss: 0.1066 || 10iter: 13.0402 sec.\n","イテレーション 5420 || Loss: 0.0909 || 10iter: 12.9723 sec.\n","イテレーション 5430 || Loss: 0.1371 || 10iter: 12.9981 sec.\n","イテレーション 5440 || Loss: 0.1110 || 10iter: 13.0049 sec.\n","イテレーション 5450 || Loss: 0.1456 || 10iter: 13.0781 sec.\n","イテレーション 5460 || Loss: 0.1851 || 10iter: 12.9943 sec.\n","イテレーション 5470 || Loss: 0.1326 || 10iter: 13.0516 sec.\n","イテレーション 5480 || Loss: 0.1004 || 10iter: 13.0059 sec.\n","イテレーション 5490 || Loss: 0.1214 || 10iter: 13.0004 sec.\n","-------------\n","（val）\n","-------------\n","epoch 30 || Epoch_TRAIN_Loss:0.1427 ||Epoch_VAL_Loss:0.1753\n","timer:  342.4023 sec.\n"]}],"source":["# 学習・検証を実行する\n","num_epochs = 30\n","train_model(net, dataloaders_dict, criterion, scheduler, optimizer, num_epochs=num_epochs)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"PSPNet_training.ipynb","provenance":[],"authorship_tag":"ABX9TyN0C8q2i49S6AgaRoZRIhnm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}